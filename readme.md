# 一些关于机器学习优化函数的练习
* p1: 最基本的梯度下降法：gradient descent 参考:
* p2: SGD方法：stochastic gradient descent 参考: http://ruder.io/optimizing-gradient-descent/index.html
* p3: minibatch-SGD方法
* p4: minibatch-SGD with momentum
* p4-2 momentum with gradient descent